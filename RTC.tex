% !Mode:: "TeX:UTF-8"
\documentclass[10pt,journal]{IEEEtran}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{comment}
\usepackage{multirow}
\usepackage{diagbox}

\graphicspath{figures/}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}

\hyphenation{on-chip real-time}

\begin{document}
\title{Delay Analysis and Buffer Sizing for Priority-Aware Networks-on-Chip (NoC)}
%\onecolumn
%\author{\IEEEauthorblockN{Baoliang Li}}

\author{Baoliang~Li, %~\IEEEmembership{Student Member,~IEEE,}
        Zeljko Zilic, %~\IEEEmembership{Senior Member,~IEEE,}
        Wenhua~Dou, %~\IEEEmembership{Non-Member,~IEEE}% <-this % stops a space
\thanks{Baoliang~Li and Wenhua Dou are with the College of Computer Science, National University of Defense Technology, Changsha 410073, P.R. China}%
\thanks{Zeljko Zilic are with Department of Electrical \& Computer Engineering, McGill University, Montreal H3A-2A7, Quebec, Canada}%
\thanks{Manuscript received XX XX, 2014; revised XX XX, 2014.}}

\markboth{Journal of XXX,~Vol.~XX, No.~XX, XX~2014}%
{Li \MakeLowercase{\textit{et al.}}: A Delay and Backlog Model for Priority-Aware Networks-on-Chip (NoC)}

\maketitle

\begin{abstract}
Among all the implementation alternatives of Networks-on-Chip (NoC), priority-aware wormhole-switched NoC is promising to meet both the worst-case and average-case performance requirements of on-chip communication. The worst-case end-to-end delay and buffer requirement analysis are very important for the development of real-time applications on this platform. In this paper, we first build a Real-Time Calculus (RTC) based performance model for the priority-aware wormhole-switched NoC. Then, we propose an end-to-end delay analysis algorithm and a buffer sizing algorithm based this model. The latency analysis algorithm can give much tighter delay bound than the existing deterministic network calculus method, since it take the maximum service capacity and minimum arrival traffic into consideration. The buffer sizing algorithm try to reduce the buffer space required for each flow without violating the deadline constraint, which improves the existing backlog bound obtained by link-level buffer-space analysis method. Our algorithms are topology-independent, taking as input the network topology graph and the traffic characterization, our algorithms can give the end-to-end delay bound and buffer requirement for each traffic flow. Our model enables the fast performance evaluation and buffer allocation of priority-aware wormhole-switched NoC, which can be used for application mapping, routing selection and power reduction, etc. Experiment results demonstrate the effectiveness and tightness of our model. In addition, further comparisons with other theoretical models also indicates that, our method outperforms the existing methods while the tightness of delay and backlog bounds are considered.
\end{abstract}
\begin{IEEEkeywords}
Networks-on-Chip (NoC), priority-aware, real-time calculus, delay bound, buffer optimization
\end{IEEEkeywords}

\section{Introduction}
The conventional on-chip interconnection paradigms, e.g. bus, ring and point-to-point links, are not able to meet the strict and complex communication requirements of modern large scale Chip-MultiProcessors (CMPs) and System-on-Chip (SoC). As an alternative, Networks-on-Chip (NoC) is proposed to provide better scalability and higher power efficiency. As a key component of CMPs and SoC, NoC must be well designed to meet the rigorous requirements on performance, power and design cost. Although various proposals have emerged, each focusing on improving different performance metrics of on-chip interconnects, e.g. end-to-end latency, throughput and power, most of the existing research on NoC are focusing on the improvement of average performance, and simulation is the most widely used performance evaluation method. Whereas, there also exists lots of on-chip applications, which are sensitive to the worst-case or real-time communication performance of NoC, e.g. cache coherent protocol \cite{Bolotin2007} and multimedia application \cite{ostermann2004video}. How to design the on-chip communication infrastructure for these applications and analyze its feasibility are of a big challenge for the researchers.

To meet the rigorous Quality-of-Service (QoS) requirement, various special hardware implementations have been proposed, e.g. Time-Division Multiplexing-Access (TDMA) \cite{GoDR05}, circuit-switch \cite{6628254} and time-triggered switch \cite{4617280}. Although providing strict real-time communication guarantee, the average performance and resource utilization of these proposals are very poor. In contrast, wormhole-switched NoC is widely used in on-chip network due to its simplicity and high-efficiency. Thus, providing real-time communication support on the conventional wormhole-switched NoC to meet both average-case and worst-case communication requirements is the most promising solution. To achieve this goal, a special scheduling policy (e.g. DifServ \cite{1411140} or priority-aware implementation \cite{Shi:2008:RCA:1397757.1397996}\cite{708526}\cite{627905}) or flow control mechanism (e.g. \cite{Li199649}\cite{707545}) should be integrated into the conventional wormhole-switched NoC. For all these real-time communication proposals based on wormhole-switched NoC, a key step before their adoption as the platform of real-time applications is the analysis of the worst-case communication delay for all the real-time flows to guarantee the satisfaction of deadline constraint. An effective buffer analysis approach is also needed to optimize the buffer allocation under real-time constraint, since buffer usually consumes about 46\% power \cite{pkundu} and occupies 30\% area \cite{5507566} of entire router.

A creditable and accurate worst-case performance analysis is crucial for the application of wormhole-switched NoC in real-time communication, since an overoptimistic estimation will lead to the violation of deadline, while an overpessimistic estimation will make the utilization of on-chip resource very low. The conventional simulation-based evaluation method is not competent for the worst-case performance analysis, because the worst-case scenarios are hard to be captured by simulation. As an alternative, the analytical method can establish the relationship between performance metrics and design parameters in a very short time, and give the worst-case performance immediately. For the worst-case analysis of fixed-priority wormhole-switched on-chip networks, Flow-Level Analysis (FLA) \cite{Shi:2008:RCA:1397757.1397996}, Link-Level Analysis (LLA) \cite{73}\cite{189} and Deterministic Network Calculus (DNC) \cite{Qian489900} have been successfully applied to analyze the end-to-end delay and backlog. Both FLA and LLA have their roots in the classic scheduling theory, which assume that the traffic flows are strictly periodic, and the buffer size of wormhole-switched NoC is sufficient large, so that the back-pressure caused by flow control can be ignored. In addition, they simplify the router model by restricting the per-hop latency to be one cycle, which is complying with the conventional router implementation.

Deterministic network calculus based method \cite{Qian489900} overcomes these limitations by applying the advanced operators and properties of DNC. However, we found that the DNC based performance bound in \cite{Qian489900} can be further improved if we take the maximal service curve of on-chip routers and minimal arrival curve of traffic into consideration. These two curves can be used to improve the tightness of output arrival curve of current router and leftover service curve of the downstream routers. The improved leftover service curve further tightens the obtained performance bounds for low-priority flows (please refer to Theorem 1.6.2 in \cite{Boudec2001Network} for more details). Motivated by this observation, we adopt the Real-Time Calculus (RTC) theory \cite{1253607} originally used for the real-time analysis of task scheduling to build an end-to-end performance model for the wormhole-switched NoC with credit-based flow control. Real-time calculus integrates the minimum arrival curve and maximum service curve into DNC theory to characterize more detailed information about the traffic and service process. Compared with the DNC model in \cite{Qian489900}, our model can significantly improves the tightness of performance bounds, we will further explain the reason and demonstrate the improvement in Section \ref{experiments}. The main contribution of this paper is twofold: (1) We propose an end-to-end delay analysis algorithm for the priority-aware wormhole-switched NoC based on the RTC model. The output of this algorithm can be used as the reference of IP core mapping, task mapping, routing selection, or NoC parameters configuration, etc. (2) We also propose an RTC based buffer sizing algorithm for the priority-aware wormhole-switched NoC to improve the buffer allocation under deadline constraint. This is a significant improvement of previously proposed FLA and LLA based buffer optimization method \cite{189}, which can be used to minimize the power consumption and chip area.

The rest of this paper is organized as follows: we present the existing real-time communication proposals and its related performance analysis methods in Section \ref{related}. In Section \ref{model}, the basic assumptions on priority-aware wormhole-switched NoC and a brief introduction to RTC theory is presented. The detailed modeling process are presented in Section \ref{modeling}, where we also propose the end-to-end delay analysis algorithm and buffer sizing algorithm. We present the experimental results and comparison with other analytical methods in Section \ref{experiments}. Finally, we summarize our paper in Section \ref{conclusion}.

\section{Related Work}\label{related}
Since first introduced in 2001 \cite{DaTo01}, various NoC proposals have emerged to meet different on-chip communication requirements. The main requirements posed to NoC by on-chip applications are latency and bandwidth. To meet these demands, NoC are designed to be either best-effort or guaranteed-service, depending on the hardware cost and application requirements. Best-effort NoC can make better use of the on-chip shared resource, but it does not necessarily provide any performance guarantee for the applications. To provide guaranteed-service for different applications, a simple and effective solution is classifying these applications into several service classes, each with different priorities, and the network provides services according to the priority of each class. Representative implementations of this idea include QNoC \cite{BCGK04}, fixed-priority NoC \cite{Shi:2008:RCA:1397757.1397996} and {{\AE}thereal} \cite{GoDR05} etc. The performance evaluation method for both best-effort and guaranteed service NoC include the average analysis and worst-case analysis. For the average analysis, simulation- and probability-based methods hold the dominant position for both of these two categories. However, for the worst-case analysis, simulation is not competent due to the difficulty in covering all the corner cases. The analytical worst case analysis for these two categories is also slightly different.

Synchronous Data Flow (SDF) graph \cite{poplavko2003task} and DNC \cite{qian2009analysis} have been presented to model the worst case performance bound of best-effort NoC. The former method assumes the traffic flow to be periodical, and the latter one eliminates this constraint to allow the traffic to be arbitrary patterns. In \cite{qian2009analysis}, the authors build an analytical performance model with DNC taking the various contention and flow control into consideration. This result is further extended in \cite{Du:2012:WPA:2380445.2380469}, where the traffic splitter is proposed to support the multi-path routing polices. Another method is presented in \cite{Lee:2003:RWC:846077.846083} to compute the worst-case delay for conventional wormhole switched network, and a real-time Wormhole Channel Feasibility Checking (WCFC) algorithm is proposed. This research is further extended to calculate the bandwidth and delay bounds in \cite{6109240}, and used for topology synthesis of best-effort NoC in \cite{EPFL-ARTICLE-186879}.

In \cite{LuJS05}, contention tree model was proposed to analyze the feasibility of real-time traffic delivered by priority-aware wormhole-switched NoC. It improves the previous results, e.g. lumped link model \cite{707545} and dependency graph model \cite{708526}, by allowing the concurrent link usage. This is similar as the the LLA \cite{73}, which improves the FLA proposed in \cite{Shi:2008:RCA:1397757.1397996} by treating each link segment separately. A comprehensive comparison among FLA, contention tree model \cite{LuJS05}, lumped link model \cite{707545} and dependency graph model \cite{708526} can be found in \cite{Shi2009}, in which several defects of previous works \cite{LuJS05}\cite{707545}\cite{708526} are illustrated and the advantages of FLA are highlighted. Two buffer sizing method based on FLA and LLA, i.e. Flow-Level Buffer-space Analysis (FLBA) and Link-Level Buffer-space Analysis (LLBA), are proposed in \cite{189} to estimate the buffer size of priority-aware wormhole-switched NoC. The main drawback of FLA and LLA is that, both these two methods assume the traffic arrives periodically and the router has single cycle latency, which are of significant simplification to the realistic traffic pattern and router implementation. In addition, the FLBA and LLBA can only compute the minimum backlog bound at each router which does not trigger the flow control. In fact, we can further reduce the buffer size as long as the the flow control does not cause the violation of deadline.

On the other hand, although the DNC based performance model for best-effort NoC proposed in \cite{qian2009analysis} can be applied to the analysis of priority-aware wormhole-switched NoC, the obtained performance bounds is very conservative, especially for the high priority flows. This is because, it does not take the priority-aware scheduling into consideration. To overcome this limitation, a revised DNC performance model is proposed to analyze the worst case delay of priority-aware wormhole-switched NoC in \cite{Qian489900}. But we found that, the DNC method in \cite{Qian489900} can be further improved if we take the maximum service curve of each router and minimum arrival curve of each flow into consideration. Motivated by this observation, we adopt the RTC theory \cite{1253607} to build the worst-case performance model for the priority-aware wormhole-switched NoC. Real-time calculus is the extension of DNC theory \cite{Boudec2001Network} by integrating the maximum service curve and minimal arrival curve, which has been widely used in the modeling and analysis of network processor \cite{1253838}, CAN \cite{4617308}, FlexRay \cite{Hagiescu:2007:PAF:1278480.1278554} and DSP systems \cite{thiele2005performance}, etc. To ease the application of RTC, a real-time calculus toolbox \cite{rtc} has also been implemented to support the numerical calculation.

\section{Preliminaries}\label{model}
\subsection{Basic Assumptions}
In this paper, we consider the same network model as the priority-aware wormhole-switched NoC proposed in \cite{627905}\cite{Shi:2008:RCA:1397757.1397996}\cite{707545}\cite{73}. Each router has the same number of input and output port, and each input port has sufficient number of FIFO buffer, i.e. Virtual Channel (VC), to accommodate all the incoming traffic of different priority levels. The allocation of VC is determined by the VC allocator. The buffer depth of each VC is finite, and credit-based flow control is adopted between each router. To ensure the predicable transmission of message, we assume that, a deterministic routine computation module is used to determine the output port of each communication message. Crossbar is used to switch traffic from input ports to the output ports, and the switch operation is determined by the switch allocator. The switch allocator is priority-aware: if multiple flits from different input ports or different VCs of the same input port contend for the same output port, it will only grant the flit with highest priority. Flits from a lower priority can transmit a flit if and only if there are no flits from higher priority in the input buffer or the flits with higher priority are self-blocked due to the insufficiency of VC buffer at downstream router. 

The router micro-architecture considered in this paper has standard 5 pipeline stages, i.e. Buffer-Write (BW), Route Computation (RC), VC Allocation (VA), Switch Allocation (SA), Switch Traversal (ST) and Link Traversal (LT). For the detailed description about the implementation and functionality of this standard router micro-architecture, please refer to \cite{jerger2009chip}. Although we focus on the standard 5-stage router, our method can be easily modified to support other router micro-architecture, e.g. single-cycle router and speculation-based router. We will demonstrate the adoption of our model in a single-cycle router in subsection \ref{llacmp}. Communication message is broken input packets, and each packet is composed of one head flit, one tail flit and several body flits. Each head flit should traverse all the five stages to find a path and reserve VC for the follow non-head flits. Non-head flits skip the RC and VA stage since the routine and VC have been determined by head flit. Router resource and control information reserved for a packet will be released only after the tail flit of this packet has been departed from the router. An additional priority field in the head flit is required for the routers to scheduling multiple contending flows according to their priority. To simplify of our analysis, we also assume that the entire chip is synchronous, with clock frequency $f$ and period $T$. Our method can also be applied to analyze Global Asynchronous Local Synchronous (GALS) NoC with little modification, because the routers located in different voltage-frequency islands can be synchronized with a half cycle synchronizer \cite{5476986}, corresponding to a fixed-latency element in DNC theory.
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[scale=0.9]{figures/mesh.pdf}\\
  \caption{Mesh topology with 4 real-time traffic flows}\label{topology}
\end{figure}

Our performance model is topology independent, but to demonstrate the basic idea of our method, we take the mesh topology shown in Fig. \ref{topology} as an example throughout this paper. The router in mesh topology has five ports, corresponding to the four cardinal directions (West, East, North and South) and the Network Interface (NI), which connects to the local Intellectual Property (IP) core. There are 4 traffic flows in Fig. \ref{topology}, i.e. $f_1$, $f_2$, $f_3$ and $f_4$. A flow is a sequence of packets with the same transmission path, source address and destination address. The path of a traffic flow is defined as a router chain started from ingress router and ended at egress router. We must emphasize that, although there is only four flows in the network, it is sufficient to demonstrate our the idea of our method, and our method can handle more traffic flows efficiently. To ensure the low latency transmission for real-time traffic flows, we have to assign higher priorities to these flows. As the minimum transmission unit in NoC is flit and a higher priority packet can preempt the transmission of a lower priority packet, the NoC architecture considered in this paper is flit-level preemptive \cite{Lee:2003:RWC:846077.846083}. Our method extends the existing methods in \cite{73}\cite{Qian489900} to allowing multiple flows share the same priority. Flits from different flows with the same priority are served in round-robin order.

\subsection{Introduction to Real-Time Calculus}\label{intrortc}
Real-time calculus \cite{1253607} is a theoretic extension of DNC \cite{Boudec2001Network}, by adding the upper service curve and lower arrival curve to describe the maximal service capacity of processing elements and minimal arrival rate of events. It is the mathematical basis of Modular Performance Analysis (MPA) \cite{Wandeler2006System} technique used for real-time task scheduling. Here we only present the definition of RTC arrival curve and service curve, for more details about this theory, please refer to \cite{1253607}.
\begin{definition}[Real-Time Arrival Curve \cite{1253607}]
Let $R[s,t)$ denote the number of events that arrived within the time interval $[s,t)$. The lower bound and upper bound on $R[s,t)$ is called the lower arrival curve $\alpha^l$ and upper arrival curve $\alpha^u$ which satisfy
$$\alpha^l(t-s)\leq R[s,t)\leq \alpha^u(t-s),\forall s<t$$
where $\alpha^l(0)=\alpha^u(0)=0$. The RTC arrival curve for $R$ is denoted as $<\alpha^l,\alpha^u>$ for short.
\end{definition}

\begin{definition}[Real-Time Service Curve \cite{1253607}]
Let $S[s,t)$ denote the total number of events that can be processed by the system in the time interval $[s,t)$. The lower bound and upper bound on $S[s,t)$ is called the lower service curve $\beta^l$ and upper service curve $\beta^u$ which satisfy
$$\beta^l(t-s)\leq S[s,t)\leq \beta^u(t-s),\forall s<t$$
where $\beta^l(0)=\beta^u(0)=0$. The RTC service curve for $S$ is denoted as $<\beta^l,\beta^u>$ for short.
\end{definition}

From the definition, we find that the upper arrival curve and lower service curve of RTC theory are corresponding to the arrival curve and service curve of DNC theory \cite{Boudec2001Network}, respectively. Similarly, the upper service curve of RTC theory is identical to the maximum service curve in DNC theory. Without explicit stated, we will use these two terms interchangeablely. In addition, the concatenation theorems for service curve (see Theorem 1.46 in \cite{Boudec2001Network}) and maximal service curve (see Theorem 1.6.1 in \cite{Boudec2001Network}) are also applicable to the RTC service curve. 

In this paper, we will utilize the discrete time RTC arrival curve and service curve to characterize the arrived traffic and service capacity, since the minimal time unit in the wormhole-switched NoC is clock period $T$. Events in arrival curve and service curve refer to the arrival and service of flits, respectively. If we obtain the arrival curve $<\alpha^l,\alpha^u>$ of a specific traffic flow and the service curve $<\beta^l,\beta^u>$ provided to this flow, we can get the output arrival curve $<\alpha^{l^\prime},\alpha^{u^\prime}>$ of this flow and leftover service curve $<\beta^{l^\prime},\beta^{u^\prime}>$ for the other flows with the following equations \cite{1253607}:
\begin{equation}\label{alphal}
\alpha^{l^\prime}=\min\{(\alpha^l\oslash\beta^u)\otimes\beta^l,\beta^l\}
\end{equation}
\begin{equation}\label{alphau}
\alpha^{u^\prime}=\min\{(\alpha^u\otimes\beta^u)\oslash\beta^l,\beta^u\}
\end{equation}
\begin{equation}\label{betal}
\beta^{l^\prime}=(\beta^l-\alpha^u)\bar{\otimes}0
\end{equation}
\begin{equation}\label{betau}
\beta^{u^\prime}=\max\{(\beta^u-\alpha^l)\bar{\oslash}0,0\}
\end{equation}
where $\otimes$, $\oslash$, $\bar{\otimes}$, $\bar{\oslash}$ are corresponding to the min-plus convolution, de-convolution, and max-plus convolution and de-convolution \cite{Boudec2001Network}, respectively.

After we obtained the arrival curve $<\alpha^l_{f_i},\alpha^u_{f_i}>$ of traffic flow $f_i$ and the service curve $<\beta_{R_j,f_i}^l,\beta_{R_j,f_i}^u>$ provided by each router $R_j$ to flow $f_i$ on its path, we can obtain the end-to-end delay bound by the following equation,
\begin{equation}\label{delay}
Delay(f_i)=H(\alpha^u_{f_i},\beta^l_{R_1,f_i}\otimes\beta^l_{R_2,f_i}\otimes\cdots\otimes\beta^l_{R_N,f_i}),
\end{equation}
where operators $H(\cdot,\cdot)$ means the maximal horizontal deviation between the two operands.

\section{Delay Analysis and Buffer Sizing}\label{modeling}
In this section, we first build an RTC based performance model for the priority-aware wormhole-switched NoC. This model consists of two parts, i.e. traffic model and service model. The traffic model utilizes the RTC arrival curve to describe the flit arrival process of each flow in the priority-aware NoC, and we will introduce two methods to obtain the arrival curve in subsection \ref{traffic}. The service model is slightly complicated than the traffic model. While constructing the service model for priority-aware wormhole-switched NoC, the follow four issues should be considered: (1) Only the head flit need to be processed by RC and VA stage, the subsequent flits of a packet just follow the data-path built by head flit. To simplify our RTC model, we need specific mechanism to characterize the service provided to head and non-head flits in a unified way. (2) Our model extends the existing approach \cite{73}\cite{Qian489900} by allowing priority sharing between flows. Thus, the leftover service curve provided to lower-priority flows can only be derived after the service curves of all the high-priority flows have been calculated. (3) Due to the limited on-chip buffer, credit-based flow control is used as a back-pressure mechanism to prevent buffer overflow. Before analysis the end-to-end delay bound with Eq.(\ref{delay}), we should first break the cyclic-dependence caused by flow control. (4) To guarantee the tightness of our theoretical performance bounds and simplify the numerical computation, we should apply the concatenation theorems as far as possible. But, this concatenation process becomes complicated when the credit-based flow control is taken into consideration. We will discuss the first two issues in subsection \ref{router}, and the last two issues are discussed in subsection \ref{flowcontrol} and subsection \ref{csp}, respectively. Based on the proposed performance model, we propose an end-to-end delay analysis algorithm and buffer sizing algorithm, as presented in subsection \ref{e2elatency} and subsection \ref{bufferopt}, respectively.

\subsection{Traffic Model}\label{traffic}
The communication in a priority-aware wormhole-switched NoC is realized by transmitting packets, and the packet is further divided into flits, which is the minimum transmission unit in wormhole-switched NoC. Denote by $<\alpha^l(\Delta),\alpha^u(\Delta)>$ the flit arrival curve of a flow, namely, the minimum and maximum number of flits can be seen within any time window of width $\Delta$. We can extract the flit arrival curve from the synthetic traffic or communication trace with the sliding window method \cite{1253607}. For each window size $\Delta$, this method tries to find the maximal and minimal number of arrived flits (corresponding to $\alpha^l(\Delta)$ and $\alpha^u(\Delta)$) by analyzing the time series of flits. The synthetic traffic or communication trace is not necessarily to be periodic, since the RTC theory makes no assumption on the periodicity of the traffic. But, the obtained flit arrival curve can only be applied to compute the worst-case performance bound at the flit level. To compute the worst-case performance bound at packet level, this arrival curve must be $L$-packetized \cite{Boudec2001Network}. Denote by $L(n)$ the cumulative packet length (in flits) of the first $n$ packets in a flow, $R(t)$ the cumulative arrived flits by time $t$. Then, the $L$-packetizer operator $\mathcal{P}^l(\cdot)$ is defined as $\mathcal{P}^L(R(t))=\underset{n\in\mathcal{N}}{\sup}\{L(n)1_{L(n)\leq R(t)}\}$\footnote{$\mathcal{N}$ is the set of natural numbers and $1_{\{val\}}$ is the indicator function, $1_{\{val\}}=1$ if and only if $val$ is true.}. Intuitively, $\mathcal{P}^l(\cdot)$ can be interpreted as the largest cumulative packet length contained in $R(t)$, as shown in Fig. \ref{lpkt}. Denote by $L_{max}$ the maximum packet length (in flits) of a flow, according to the basic properties of $L$-packetizer \cite{Boudec2001Network}, we have
$$R(t)-l_{max}\leq \mathcal{P}^L(R(t))<R(t)$$
and
$$R(s)-l_{max}\leq \mathcal{P}^L(R(s))<R(s)$$
which indicate
$$\alpha(t-s)^l-l_{max}<\mathcal{P}^L(R(t))-\mathcal{P}^L(R(s))<\alpha(t-s)^u+l_{max}.$$
The inequalities above indicate that, if a flow has a flit arrival curve $<\alpha^l(\Delta),\alpha^u(\Delta)>$, the $L$-packetized flow has a packet arrival curve $<\alpha^l(\Delta)-l_{max}1_{\{\Delta>0\}},\alpha^u(\Delta)+l_{max}1_{\{\Delta>0\}}>$. We can also directly obtain the $L$-packetized arrival curve instead of transformation from flit arrival curve for some special cases. For example, suppose all the packets in a flow have the same length $F$ and arrived periodically with period $I$. We can obtain the flit arrival curve of this flow by applying the sliding window method, as shown in Fig. \ref{perio}. The obtained flit arrival curve is equivalent to the $L$-packetized arrival curve $\mathcal{P}^L(\alpha)$, since $\mathcal{P}^L(R(t))=R(t)$ and $\mathcal{P}^L(\alpha(t))=\alpha(t)$.
\begin{figure}
  \centering
  \subfloat[]{\includegraphics[scale=0.35]{figures/LPKT.pdf}\label{lpkt}}\hspace{10pt}
  \subfloat[]{\includegraphics[scale=0.35]{figures/AC.pdf}\label{perio}}
  \caption{Traffic model. (a) Definition of $\mathcal{P}^L(R(t))$. Cumulative arrival function $R(t)$ and the $L$-packetized cumulative arrival function $\mathcal{P}^L(R(t))$ are represented by the dotted line and solid line, respectively. (b) Real-time calculus arrival curve for periodically arrived traffic with period $I$ and packet length $F$. The solid line and dotted line represent the upper arrival curve and lower arrival curve.}\label{ac}
\end{figure}

\subsection{Service Model}\label{router}
While modeling the service capacity of routers with RTC, we can analyze the data-path of a flow stage-by-stage. After obtained the service curve for each stage, the service curve provided by the router to the flow can be obtained by concatenating all the service curves of these five stages. This is significantly different with the existing DNC based model \cite{qian2009analysis,Qian489900}, where they treat the entire router as a whole and designate a Latency-Rate (LR) service curve for simplicity. The advantage of our method is that, it can be easily modified to characterize the non-standard router micro-architectures, by simply letting the service curve of non-existed stages to be burst delay function $\delta_0(t)$\footnote{$\delta_0(t)=+\infty$ if $t>0$, and 0 otherwise.}. Next, we try to obtain the service curves of all these 5 stages:
\begin{figure}
  \centering
  \subfloat[]{\includegraphics[scale=0.35]{figures/BW_ST_SA.pdf}\label{result1}}\hspace{10pt}
  \subfloat[]{\includegraphics[scale=0.35]{figures/RC_VA.pdf}\label{result2}}
  \caption{Service model for each pipeline stages. The solid lines and dotted lines represent the upper service curves and lower service curves, respectively. (a) Service curve of BW, SA and ST stages; (b) Service curve of RC and VA stages.}
\end{figure}

(1) BW stage and ST stage: all the flits within a traffic flow will traverse these two stages, and experience a fixed delay $T$. Take the BW stage as an example, for any time interval of length less than $T$, the maximum and minimal number of flits can be served are one and zero, respectively, since it outputs one flit at each cycle $T$. Similarly, for any time interval of length greater than $T$, the maximum and minimal number of flits that can be seen are two and one, respectively. The resulted service curves, i.e. $<\beta^l_{BW},\beta^u_{BW}>$ and $<\beta^l_{ST},\beta^u_{ST}>$, are shown in Fig. \ref{result1}.

(2) RC stage and VA stage: the traverse latency of head flit and non-head flits at these two stages are $T$ and 0, respectively. A sophisticated solution to construct a unified service curve for head flit and non-head flits at these two stages is that, we can view these two stages can service an entire packet within $T$ period. Suppose the packet length is $F$, the equivalent service curve for these two stages, i.e. $<\beta^l_{RC},\beta^u_{RC}>$ and $<\beta^l_{VA},\beta^u_{VA}>$, can be easily obtained by amplifying the service curve of Fig. \ref{result1} in $y$-axis with a factor $F$, as shown in Fig. \ref{result2}.

(3) SA stage: each output port in the wormhole-switched NoC has a SA scheduler to schedule the switch traversal at each cycle. Thus, following the same approach as BW and ST stage, we can get the service curve $<\beta_{SA,R_i}^l,\beta_{SA,R_i}^u>$ provided by SA stage of router $R_i$ to all the contention flows, as shown in Fig. \ref{roundrobin}a. For the fixed-priority based scheduling policy, switch allocators provide service for high priority flows first, and flows with the same priority will be served with Round-Robin order. The unserved flows will be imposed an additional latency $T$ due the failure of switch arbitration.

Denote by $<\beta_{SA,R_i,f_j}^l,\beta_{SA,R_i,f_j}^u>$ the service curve provided to flow $f_j$ by SA stage of router $R_i$, the equivalent service curve of router $R_i$ provided to $f_j$, i.e. $<\beta_{R_i,f_j}^l,\beta_{R_i,f_j}^u>$, can be obtained by concatenating the service curves of all the 5 stages together:
$$\beta_{R_i,f_j}^l=\beta_{BW}^l\otimes\beta_{RC}^l\otimes\beta_{VA}^l\otimes\beta_{SA,R_i,f_j}^l\otimes \beta_{ST}^l,$$
$$\beta_{R_i,f_j}^u=\beta_{BW}^u\otimes\beta_{RC}^u\otimes\beta_{VA}^u\otimes\beta_{SA,R_i,f_j}^u\otimes \beta_{ST}^u.$$

The alert readers would notice that, the contention of different flows only occurs at SA stage. Thus, if we obtained the service curve provided by SA stage to flow $f_j$, we can obtain the service curve of router directly. Suppose the total service curve provided by SA stage is $<\beta_{SA,R_i}^l,\beta_{SA,R_i}^u>$ and the leftover service curve after serving flows with higher priority than $f_j$ is $<\beta_{SA,R_i}^{l^\prime},\beta_{SA,R_i}^{u^\prime}>$, to obtain the service curve $<\beta_{SA,R_i,f_j}^l,\beta_{SA,R_i,f_j}^u>$, we should consider the following two cases:

(a) all the flows contending with $f_j$ at $R_i$ have lower priorities. For the synchronize router architecture, flow $f_j$ obtain the total leftover service curve $<\beta_{SA,R_i}^{l^\prime},\beta_{SA,R_i}^{u^\prime}>$.

(b) there exists some contention flows with the same priority as $f_j$. Denote by $\Theta_{R_i,f_j}$ the set of contention flows at router $R_i$ with the same priority as $f_j$, and let $N_{R_i,f_j}$ be the number of flows in $\Theta_{R_i,f_j}$. Since all the flows in $\Theta_{R_i,f_j}$ got serviced in Round-Robin order, the service curve provided to $f_j$ is $<\lfloor\beta^{l^\prime}_{SA,R_i}/(N_{R_i,f_j}+1)\rfloor,\lceil\beta^{u^\prime}_{SA,R_i}/(N_{R_i,f_j}+1)\rceil>$, where $\lceil\cdot\rceil$ and $\lfloor\cdot\rfloor$ are the ceiling operator and flooring operator. This is slightly different from the conventional continuous time model which is $<\beta^{l^\prime}_{SA,R_i}/(N_{R_i,f_j}+1),\beta^{u^\prime}_{SA,R_i}/(N_{R_i,f_j}+1)>$. An example with two flows with the same priority is shown in Fig. \ref{roundrobin}. After serving by all the flows in $\Theta_{R_i,f_j}$, the leftover service capacity for low priority flows can be obtained by applying Eq.(\ref{betal}) and Eq.(\ref{betau}).
\begin{figure*}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[scale=0.5]{figures/RoundRobin.pdf}\\
  \caption{Service curve of SA stage for two flows with the same priority under Round-Robin scheduling policy. (a) Service capacity of SA stage. (b) Upper and lower service curve provided to each contending flow, corresponding to the solid line and dotted line; the solid green line and dotted red line represent the unrounded upper and lower service curves.}\label{roundrobin}
\end{figure*}

\subsection{Upper Service Curve of Flow Controller}\label{flowcontrol}
Credit-based flow control introduces cyclic-dependence between the adjacent routers, and leads to the self-blocking within a flow due to the insufficiency of buffer space at the downstream router. To make the discussion concrete, we take flow $f_2$ as an example and utilize the scheduling network \cite{1253607} in RTC theory to visualize the credit-based flow control and complex interaction between $f_2$ and the other flows, as shown in Fig. \ref{f2}. We ignore flow $f_4$ and the flow control of other flows for simplicity. We also assume that, the destination IP core can consume the ejected flits immediately, thus there is no flow control between the ejection router and destination NI. But, to prevent the buffer overflow, the flow control between input NI and injection router is necessary. The flow control mechanism introduces feedback control loop between adjacent routers, preventing us from deriving the performance bound directly even after we have obtained the service curve reserved at each router for the target flow. Historically, this issue is addressed  by fixed-point iteration \cite{schioler2005network} or transformation from marked dataflow graph \cite{Thiele:2009:MPA:1629335.1629353}. In this paper, we try to tackle the same problem with another solution. This is motivated by \cite{qian2009analysis}, where the authors abstract the flow control as a network element (called flow controller) providing a service curve $\beta_{\tau}$ (corresponding to the lower service curve in RTC theory), which can be obtained by applying some basic properties of dioid algebra.
\begin{figure*}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[scale=0.35]{figures/f2.pdf}\\
  \caption{Scheduling network model for flow $f_2$}\label{f2}
\end{figure*}

In this subsection, we follow the same procedure as \cite{qian2009analysis} to derive the upper service curve for the flow controller, as summarized in Theorem \ref{credit}. The obtained upper service curve together with the lower service curve derived in \cite{qian2009analysis} enable us to break the control loop caused by flow control and build a comprehensive performance model with RTC.
\begin{theorem}\label{credit}
Suppose the router provides an upper service curve $\beta^u$, the buffer size and credit feedback delay are denoted as $B$ and $\sigma$. Then the flow controller provides an equivalent upper service curve $$\beta^{u}_\tau(t)=\overline{\beta^u\otimes\delta_\sigma(t)+B}$$ where $\bar{f}$ is the sub-additive closure of $f$ \cite{Boudec2001Network} and $\delta_\sigma(t)=+\infty$ for $\forall t>\sigma$, otherwise $\delta_\sigma(t)=0$.
\end{theorem}
\begin{IEEEproof}
We take the flow control between $R_9$ and $R_5$ in Fig. \ref{f2} as an example to proof this theorem. Denote the amount of injected and departed flits at $R_5$ by time $t$ as $I(t)$ and $D(t)$, and the amount of flits served by $R_9$ by time $t$ is denoted as $A(t)$. The feedback link can be represented as a network element providing upper service curve $\delta_\sigma(t)$. Next, we apply the basic properties of service curve and dioid algebra to derive the upper service curve this flow controller. We have $I(t)=\min\{A(t),D^\prime(t)+B\}$ by the property of credit-based flow control, where $D^\prime=D\otimes\delta_\sigma$.

Based on property of upper service curve $\beta^u$, we have\footnote{An alternative definition of upper service curve, see definition 1.6.1 in \cite{Boudec2001Network} for more details.}
$$D(t)\leq I\otimes \beta^u(t).$$

Bring $I(t)$ and $D^\prime(t)$ into this equality, we get
\begin{eqnarray*}
D(t)&\leq& I\otimes \beta^u(t)\\
&\leq& \min\{A\otimes \beta^u(t),D\otimes\delta_\sigma\otimes \beta^u(t)+B\}.
\end{eqnarray*}
By applying Theorem 4.31 in \cite{Boudec2001Network}, we have
$$D\leq A\otimes \beta^u\otimes\overline{\beta^u\otimes\delta_\sigma+B}.$$
Thus,
\begin{eqnarray*}
  I&=& \min\{A,D^\prime+B\}\\
  &\leq& \min\{A,D\otimes\delta_\sigma+B\}\\
  &\leq& \min\{A,A\otimes \beta^u\otimes\overline{\beta^u\otimes\delta_\sigma+B}\otimes\delta_\sigma+B\}\\
  &=& \min\{A\otimes \delta_\sigma,A\otimes (\beta^u\otimes\delta_\sigma+B)\otimes\overline{\delta_\sigma\otimes\beta^u+B}\}\\
  &=& \min\{A\otimes \delta_\sigma,A\otimes \overline{\delta_\sigma\otimes\beta^u+B}\}\\
  &=& A\otimes\min\{\delta_\sigma,\overline{\beta^u\otimes\delta_\sigma+B}\}\\
  &=& A\otimes\overline{\beta^u\otimes\delta_\sigma+B}.
\end{eqnarray*}
which implies that, the flow controller has an equivalent upper service curve $\overline{\beta^u\otimes\delta_\sigma+B}$.
\end{IEEEproof}

Theorem \ref{credit} derives the upper service curve of a single flow controller, and we can get the service curves of all the flow controllers along the router chain of all the flows by applying Theorem \ref{credit} iteratively. As shown in Fig. \ref{f2}, the service curve of downstream routers can affect the service curve of flow controller at upstream. Hence, we should compute the service curves of flow controller from ejection router to injection router. Take flow $f_2$ as an example, we should first derive the service curves of $f_2$ obtained at each router with the method provided in Subsection \ref{router}. Service curve obtained at Router $R_{15}$ to flow $f_2$ can be derived by applying Eq.(\ref{betal}) and Eq.(\ref{betau}), since $f_2$ is a lower priority flow at $R_{15}$. Router $R_{13}$, $R_{9}$ and $R_{5}$ provide all their service capacity to $f_2$ because $f_2$ is the highest priority flow at these routers. Then, the service curve of flow controller at router $R_{9}$ can be obtained by applying Theorem \ref{credit}, which is $<\beta_{\tau_9}^l,\beta_{\tau_9}^u>$. By applying the concatenation theorem, we can obtain the equivalent service curve of router $R_{9}$ are $<\beta_{R_9}^l\otimes\beta_{\tau_9}^l,\beta_{R_9}^u\otimes\beta_{\tau_9}^u>$. Follow the same procedure, we can get the service curve of flow controller at router $R_{13}$, $R_{14}$, $R_{15}$ and the source NI that connected to $R_{15}$ iteratively.

\subsection{Collapsible Sub-Path}\label{csp}
To this end, we have build the traffic model, router model and flow control model in the previous subsections. Before giving the delay analysis algorithm algorithm, we first consider the follow scenario. Flow $f_2$ and $f_3$ in Fig. \ref{topology} contend the output link at both router $R_{13}$ and $R_{9}$. Suppose $P_2>P_3$ and denote by $B_{R_9,f_2}$ the buffer size of router $R_{9}$ allocated to flow $f_2$, $<\beta_{R_{13},f_2}^l,\beta_{R_{13},f_2}^u>$ and $<\beta_{R_{9},f_2}^l,\beta_{R_{9},f_2}^u>$ the service curve provided to flow $f_2$ by router $R_{13}$ and $R_{9}$, $<\beta_{\tau_{13},f_2}^l,\beta_{\tau_{13},f_2}^u>$ the service curve for flow controller of router $R_{13}$, $<\alpha_{R_{13},f_2}^l,\alpha_{R_{13},f_2}^u>$ and $<\alpha_{R_{13},f_3}^l,\alpha_{R_{13},f_3}^u>$ the arrival curve of $f_2$ and $f_3$ at router $R_{13}$. The question is: when $B_{R_9,f_2}$ is sufficiently large so that $\beta_{R_{13},f_2}^l\otimes\beta_{\tau_{13},f_2}^l=\beta_{R_{13},f_2}^l$ and $\beta_{R_{13},f_2}^u\otimes\beta_{\tau_{13},f_2}^u=\beta_{R_{13},f_2}^u$, how to derive the leftover service curve for $f_3$ at $R_{13}$ and $R_9$, and obtain a tight performance bound of $f_3$ efficiently?

An intuitive solution is: Firstly, obtaining the leftover service curve of $R_{13}$ by applying Eq.(\ref{betal}) and Eq.(\ref{betau}); Secondly, deriving the output arrival curve $<\alpha_{R_{9},f_2}^{l^\prime},\alpha_{R_{9},f_2}^{u^\prime}>$ of $f_2$ by applying Eq.(\ref{alphal}) and Eq.(\ref{alphau}); Thirdly, the leftover service curve of $R_9$ can be easily obtained by applying Eq.(\ref{betal}) and Eq.(\ref{betau}); And finally, the leftover service curve for $f_3$ at $R_{13}$ and $R_9$ can be easily obtained by concatenating these two service curves. Another solution is: we can substitute $R_{13}$ and $R_{9}$ by a virtual router $R_{13,9}$ providing service curve $<\beta_{R_{13},f_2}^l\otimes\beta_{R_{13},f_2}^l,\beta_{R_{13},f_2}^u\otimes\beta_{R_{13},f_2}^u>$, since $B_{R_9,f_2}$ is sufficiently large and the flow control between $R_{13}$ and $R_9$ can be ignored, as shown in Fig. \ref{collapse}. Then, the service curve of $f_3$ obtained at $R_{13}$ and $R_{9}$ can be directly obtained by applying Eq.(\ref{betal}) and Eq.(\ref{betau}). Compared with previous router-by-router calculation method, it eliminates the calculation of intermediate arrival curve, and compute the equivalent service curve by just invoke Eq.(\ref{betal}) and Eq.(\ref{betau}) once, which is of calculating efficiency. We formalize this observation and propose the concept of Collapsible Sub-Path (CSP) to simplify the calculation and improve the tightness of performance bounds.
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[scale=0.5]{figures/collapse.pdf}\\
  \caption{Collapsible sub-path of $f_2$. Since the flow control between $R_{13}$ and $R_9$ can be ignored, they are replaced by a single virtual router $R_{13,9}$.}\label{collapse}
\end{figure}

\begin{definition}[Collapsible Sub-Path]
The collapsible sub-path of flow $f$, denoted by $CSP(f)$, is a sub-path of $f$ satisfying the follow conditions:
\begin{enumerate}
  \item all the routers $R_i$ on this sub-path, except the last one, satisfy $\beta_{R_{i},f}^l\otimes\beta_{\tau_{i},f}^l=\beta_{R_{i},f}^l$ and $\beta_{R_{i}，f}^u\otimes\beta_{\tau_{i},f}^u=\beta_{R_{i},f}^u$.
  \item $CSP(f)$ is also a sub-path of all the flows in $\Omega_{f}$, where $\Omega_{f}$ is the set of contention flows with lower priorities on this sub-path.
\end{enumerate}
\end{definition}

For the high-priority flows, the process of calculating the end-to-end equivalent service curve with concatenation theorem is also a collapsing process. But, to compute the leftover service curve for low-priority flows at some routers, we have to know the arrival curve of high-priority flows at these routers. As implied previously, instead of the router-by-router calculation, we can leverage the concept of CSP and replace all the routers on $CSP(f)$ with a single virtual router providing service curve $<\otimes_{R_i\in CSP(f)}\beta_{R_i,f}^l,\otimes_{R_i\in CSP(f)}\beta_{R_i,f}^u>$. For a CSP with $n$ ($n\geq 2$) routers, this method reduces $n-1$ times calculation of arrival curve and leftover service curve. The leftover service curve calculation is greatly simplified, and the accuracy of performance bound is also improved due to the well-known ``Pay-Burst-Only-Once" phenomenon in DNC theory \cite{Boudec2001Network}.

\subsection{End-to-End Delay Analysis}\label{e2elatency}
After obtained the traffic model, service model and flow control model, compute the end-to-end delay is still a non-trivial task. The follow four aspects should be considered carefully: (1) We should always compute the end-to-end delay by collapsing all the CSP to a single virtual node, as the hop-by-hop computation will lead to a looser bound; (2) In the fixed-priority flit-level preemptive NoC, only the leftover service curve can be used by the low-priority flows, thus, the computation process must start from high-priority flows to low-priority flows; (3) Our performance model supports priority-sharing, before computing the leftover service curve for lower priority flows, we must ensure that all the flows with the same priority have been calculated; (4) The computed service curve for flow controller can only be applicable for specific flow, and we should compute these curves for each flows. Keeping these four aspects in mind, we propose the performance evaluation algorithm, as shown in Algorithm \ref{alg:equivalentservicecurve}.
\begin{algorithm}
\caption{End-to-End Delay Analysis Algorithm}
\label{alg:equivalentservicecurve}
\begin{algorithmic}[1]
\REQUIRE Network Topology Graph and Flow Specification
\ENSURE Worst-case End-to-End Delay for all the flows
    \FOR {each flow $f_i\in \mathcal{F}$ with priority order}
        \STATE $\beta_{\tau}^l=\delta_0(t)$; $\beta_{\tau}^u=\delta_0(t)$;
        \FOR {each router $R_j\in \mathcal{R}_{i}$ from $end_i$ to $start_i$}
            \IF {$\Theta_{R_j,f_i}\neq \emptyset$}
                \STATE $\beta_{R_j,f_i}^l=\beta_{BW}^l\otimes\beta_{RC}^l\otimes\beta_{VA}^l\otimes\lfloor\frac{\beta_{SA,R_j}^{l^\prime}}{N_{R_j,f_i}+1}\rfloor\otimes\beta_{ST}^l$;
                \STATE $\beta_{R_j,f_i}^u=\beta_{BW}^u\otimes\beta_{RC}^u\otimes\beta_{VA}^u\otimes\lceil\frac{\beta_{SA,R_j}^{u^\prime}}{N_{R_j,f_i}+1}\rceil\otimes\beta_{ST}^u$;
            \ELSE
                \STATE $\beta_{R_j,f_i}^l=\beta_{BW}^l\otimes\beta_{RC}^l\otimes\beta_{VA}^l\otimes\beta_{SA,R_j}^{l^\prime}\otimes\beta_{ST}^l$;
                \STATE $\beta_{R_j,f_i}^u=\beta_{BW}^u\otimes\beta_{RC}^u\otimes\beta_{VA}^u\otimes\beta_{SA,R_j}^{u^\prime}\otimes\beta_{ST}^u$;
            \ENDIF
            \STATE $\beta^{l}_{\tau_j,f_i}(t)=\beta_{\tau}^l$; $\beta_{\tau}^l=\overline{\beta^l_{R_j,f_i}\otimes\beta^{l}_{\tau}\otimes\delta_\sigma(t)+B_{R_j,f_i}}$;
            \STATE $\beta^{u}_{\tau_j,f_i}(t)=\beta_{\tau}^u$; $\beta_{\tau}^u=\overline{\beta^u_{R_j,f_i}\otimes\beta^{u}_{\tau}\otimes\delta_\sigma(t)+B_{R_j,f_i}}$;
        \ENDFOR
        \STATE Collapse $CSP(f_i)$ and update $\Theta_{R_j,\cdot}$, $\Omega_{R_j,\cdot}$ and $\mathcal{R}_{\cdot}$;
        \STATE $Delay(f_i)=H(\alpha^u_{f_i},\underset{R_k\in\mathcal{R}_{f_i}}{\otimes}(\beta^l_{R_k,f_i}\otimes\beta^l_{\tau_k,f_i}))$;
        \STATE $\beta_{f_i}^l=\delta_0(t)$; $\beta_{f_i}^u=\delta_0(t)$;
        \FOR {For $\forall R_j\in\mathcal{R}_{f_i}$ from $start_i$ to $end_i$}
            \STATE $\beta^l=\beta^l_{f_i}\otimes\beta_{BW}^l\otimes\beta_{RC}^l\otimes\beta_{VA}^l$;
            \STATE $\beta^u=\beta^u_{f_i}\otimes\beta_{BW}^u\otimes\beta_{RC}^u\otimes\beta_{VA}^u$;
            \STATE $\alpha^l_{R_j,f_i}=\min\{(\alpha^l_{f_i}\oslash\beta^u)\otimes\beta^l,\beta^l\}$;
            \STATE $\alpha^u_{R_j,f_i}=\min\{(\alpha^u_{f_i}\otimes\beta^u)\oslash\beta^l,\beta^u\}$;
            \STATE $\beta_{f_i}^l=\beta_{f_i}^l\otimes\beta_{R_j,f_i}^l\otimes\beta^l_{R_j,f_i}$;
            \STATE $\beta_{f_i}^u=\beta_{f_i}^u\otimes\beta_{R_j,f_i}^u\otimes\beta_{R_j,f_i}^u$;
            \IF {$\Omega_{R_j,f_i}\neq \emptyset$}
                \IF {delay of $\forall f_k\in\Theta_{R_j,f_i}$ has been calculated}
                    \STATE $\alpha^l_{R_j,f_i}=\alpha^l_{R_j,f_i}+\sum_{f_k\in\Theta_{R_j,f_i}}\alpha^l_{R_j,f_k}$;
                    \STATE $\alpha^u_{R_j,f_i}=\alpha^u_{R_j,f_i}+\sum_{f_k\in\Theta_{R_j,f_i}}\alpha^u_{R_j,f_k}$;
                \ENDIF
                \STATE $\beta^{l^\prime}_{SA,R_j}=(\beta^{l^\prime}_{SA,R_j}-\alpha^u_{R_j,f_i})\bar{\otimes}0$;
                \STATE $\beta^{u^\prime}_{SA,R_j}=\max\{(\beta^{u^\prime}_{SA,R_j}-\alpha^l_{R_j,f_i})\bar{\oslash}0,0\}$;
            \ENDIF
        \ENDFOR
    \ENDFOR
\end{algorithmic}
\end{algorithm}

Suppose the entire NoC is represented as a directional topology graph $G:\ V\times E$, where $V$ and $E$ represent the set of routers and links, respectively. For each link $e_{i,j}\in E$ represent there is a physical channel between router $R_i$ and router $R_j$, $e_{i,j}\neq e_{j,i}$ since the topology graph is a directional graph. The set of all the flows in the network is denoted as $\mathcal{F}$, and each flow $f_i\in\mathcal{F}$ has a fixed-priority $P_i$ and deadline $D_i$. The set of routers a flow $f_i$ traversed is denoted as $\mathcal{R}_i$, and the set of links a flow $f_i$ traversed is denoted as $\Gamma_i$. If there exists interference between flow $f_i$ and $f_j$, then $\Gamma_i\wedge\Gamma_j\neq\Phi$ and the set of contention routers is $\mathcal{R}_i\wedge\mathcal{R}_j$. Denote by $<\alpha_{f_i}^l,\alpha_{f_i}^u>$ the arrival curve of flow $f_i$ at the ingress port, $<\alpha_{R_j,f_i}^l,\alpha_{R_j,f_i}^u>$ the arrival curve of $f_i$ at router $R_j$, and $<\beta_{SA,R_j}^{l^\prime},\beta_{SA,R_j}^{u^\prime}>$  the leftover service curve of SA stage at router $R_j$ (Initially, $\beta_{SA,R_j}^{l^\prime}=\beta_{SA,R_j}^{l}$ and $\beta_{SA,R_j}^{u^\prime}=\beta_{SA,R_j}^{u}$). The path of flow $f_i$ is started from ingress router (denoted by $start_i$) to egress router (started by $end_i$). For all the router $R_j$ along the path of flow $f_i$, denote the contention flows sharing the same priority with $f_i$ as $\Theta_{R_j,f_i}$, the set with lower priority flow as $\Omega_{R_j,f_i}$, and the buffer size as $B_{R_j,f_i}$. In addition, let $N_{R_j,f_i}$ and $N_{f_i}$ be the number of flows in $\Theta_{R_j,f_i}$ and the number of routers that $f_i$ traversed.

The proposed algorithm calculates the end-to-end delay from high-priority flows to low-priority flows, and for each iteration, performs the following four steps: (1) Calculating the service curve provided by router (lines 4-10) and flow controller (lines 11-12); (2) Identifying and collapsing all the CSP on the path of a flow to improve the analyzing accuracy (line 14); (3) Computing the worst-case end-to-end delay (line 15); (4) Calculating the leftover service curve for low-priority flows (lines 16-32). We also need to emphasize that, the leftover service curve for lower priority flows should compute after all the service curve of higher priority flows have been calculated, as implied by line 25 in Algorithm 1. The overall algorithm has two-level embedded loops, and the computation complexity for this algorithm is $O(pN)$, where $N$ and $p$ is the number of flows and the hop count of each flow. This algorithm is of pseudo-polynomial complexity due to the computation complexity of algorithmic min-plus convolution and sub-additive closure \cite{Bouillard2008}. This algorithm can be easily integrated into the RTC toolbox \cite{rtc} to compute the end-to-end delay automatically.

\subsection{Buffer Sizing}\label{bufferopt}
The priority-aware wormhole-switched NoC \cite{Shi:2008:RCA:1397757.1397996} requires the same amount of VC as the priorities to prevent priority inversion \cite{707545}, which refers to the blocking of high-priority flows when the low-priority flows occupy all the VCs. To reduce the buffer area and power consumption, priority sharing \cite{5161497} and buffer optimization \cite{189} techniques are proposed. However, the two backlog bounds derived in \cite{189} is the minimum buffer size that does not trigger the flow control, which can be further reduced as long as the constraint of deadline is not be violated. Suppose the application has been mapped onto the NoC, and each flow $f_i$ has been assigned to their corresponding priority $P_i$ and deadline $D_i$. Following the same notations as Algorithm 1, we propose the buffer optimization algorithm to further reduce the buffer size, as shown in Algorithm \ref{alg:bufopt}. It tries to optimize the buffer size for each flow from high-priority to low-priority gradually. For each iteration, it performs the following four steps: (1) Calculating the service curve provided by router (lines 3-9); (2) Calculate the minimum buffer size that can avoid flow control (lines 10-13); (3) Reduce the initial buffer size gradually as long as the constraint of deadline is not violated (lines 15-26); (4) Calculating the leftover service curve for low-priority flows (lines 27-43). This algorithm can be implemented in RTC toolbox \cite{rtc} to optimize the buffer size automatically. The entire computation complexity is $O(pN)$, where $N$ and $p$ are the number of flows and the number of routers along the path. This complexity is pseudo-polynomial due to the end-to-end delay calculation.
\begin{algorithm}
\caption{Buffer Sizing Algorithm}
\label{alg:bufopt}
\begin{algorithmic}[1]
\REQUIRE Network Topology Graph and Flow Specification
\ENSURE Optimized Buffer Size
    \FOR {each flow $f_i\in \mathcal{F}$ with priority order}
        \FOR {each router $R_j\in \mathcal{R}_{i}$}
            \IF {$\Theta_{R_j,f_i}\neq \emptyset$}
                \STATE $\beta_{R_j,f_i}^l=\beta_{BW}^l\otimes\beta_{RC}^l\otimes\beta_{VA}^l\otimes\lfloor\frac{\beta_{SA,R_j}^{l^\prime}}{N_{R_j,f_i}+1}\rfloor\otimes\beta_{ST}^l$;
                \STATE $\beta_{R_j,f_i}^u=\beta_{BW}^u\otimes\beta_{RC}^u\otimes\beta_{VA}^u\otimes\lceil\frac{\beta_{SA,R_j}^{u^\prime}}{N_{R_j,f_i}+1}\rceil\otimes\beta_{ST}^u$;
            \ELSE
                \STATE $\beta_{R_j,f_i}^l=\beta_{BW}^l\otimes\beta_{RC}^l\otimes\beta_{VA}^l\otimes\beta_{SA,R_j}^{l^\prime}\otimes\beta_{ST}^l$;
                \STATE $\beta_{R_j,f_i}^u=\beta_{BW}^u\otimes\beta_{RC}^u\otimes\beta_{VA}^u\otimes\beta_{SA,R_j}^{u^\prime}\otimes\beta_{ST}^u$;
            \ENDIF
            \STATE $B^l=\inf\{B|\beta_{R_j,f_i}^l\otimes\overline{\beta_{R_j,f_i}^l\otimes\delta_\sigma(t)+B}\geq\beta_{R_j,f_i}^l\}$;
            \STATE $B^u=\inf\{B|\beta_{R_j,f_i}^u\otimes\overline{\beta_{R_j,f_i}^u\otimes\delta_\sigma(t)+B}\geq\beta_{R_j,f_i}^u\}$;
            \STATE $B_{R_j,f_i}=\max\{B^l,B^u\}$;
            \STATE $\beta_{\tau_j,f_i}^l=\delta_0(t)$; $\beta_{\tau_j,f_i}^u=\delta_0(t)$;
        \ENDFOR
        \FOR {each router $R_j\in \mathcal{R}_{i}$ from $end_i$ to $start_i$}
            \STATE $Delay(f_i)=H(\alpha^u_{f_i},\underset{R_k\in\mathcal{R}_{f_i}}{\otimes}(\beta^l_{R_k,f_i}\otimes\beta^l_{\tau_k,f_i}))$;
            \WHILE {$Delay(f_i)\leq D_i$ and $B_{R_j,f_i}>1$}
                \STATE $B_{R_j,f_i}=B_{R_j,f_i}-1$;
                \STATE Recalculate $\beta_{\tau_k,f_i}^l$ for all $R_{k}$ from $R_j$ to $start_i$;
                \STATE $Delay(f_i)=H(\alpha^u_{f_i},\underset{R_k\in\mathcal{R}_{f_i}}{\otimes}(\beta^l_{R_k,f_i}\otimes\beta^l_{\tau_k,f_i}))$;
            \ENDWHILE
            \IF {$Delay(f_i)>D_i$}
                \STATE $B_{R_j,f_i}=B_{R_j,f_i}+1$;
                \STATE Update $<\beta_{\tau_j,f_i}^l,\beta_{\tau_j,f_i}^u>$;
            \ENDIF
        \ENDFOR
        \STATE $\beta_{f_i}^l=\delta_0(t)$; $\beta_{f_i}^u=\delta_0(t)$;
        \FOR {For $\forall R_j\in\mathcal{R}_{f_i}$ from $start_i$ to $end_i$}
            \STATE $\beta^l=\beta^l_{f_i}\otimes\beta_{BW}^l\otimes\beta_{RC}^l\otimes\beta_{VA}^l$;
            \STATE $\beta^u=\beta^u_{f_i}\otimes\beta_{BW}^u\otimes\beta_{RC}^u\otimes\beta_{VA}^u$;
            \STATE $\alpha^l_{R_j,f_i}=\min\{(\alpha^l_{f_i}\oslash\beta^u)\otimes\beta^l,\beta^l\}$;
            \STATE $\alpha^u_{R_j,f_i}=\min\{(\alpha^u_{f_i}\otimes\beta^u)\oslash\beta^l,\beta^u\}$;
            \STATE $\beta_{f_i}^l=\beta_{f_i}^l\otimes\beta_{R_j,f_i}^l\otimes\beta_{\tau_j,f_i}^l$;
            \STATE $\beta_{f_i}^u=\beta_{f_i}^u\otimes\beta_{R_j,f_i}^u\otimes\beta_{\tau_j,f_i}^u$;
            \IF {$\Omega_{R_j,f_i}\neq \emptyset$}
                \IF {delay of $\forall f_k\in\Theta_{R_j,f_i}$ has been calculated}
                    \STATE $\alpha^l_{R_j,f_i}=\alpha^l_{R_j,f_i}+\sum_{f_k\in\Theta_{R_j,f_i}}\alpha^l_{R_j,f_k}$;
                    \STATE $\alpha^u_{R_j,f_i}=\alpha^u_{R_j,f_i}+\sum_{f_k\in\Theta_{R_j,f_i}}\alpha^u_{R_j,f_k}$;
                \ENDIF
                \STATE $\beta^{l^\prime}_{SA,R_j}=(\beta^{l^\prime}_{SA,R_j}-\alpha^u_{R_j,f_i})\bar{\otimes}0$;
                \STATE $\beta^{u^\prime}_{SA,R_j}=\max\{(\beta^{u^\prime}_{SA, R_j}-\alpha^l_{R_j,f_i})\bar{\oslash}0,0\}$;
            \ENDIF
        \ENDFOR
    \ENDFOR
\end{algorithmic}
\end{algorithm}

A significant difference with Algorithm 1 is that, this algorithm does not identify and collapse the CSP, because the reduction of buffer size introduces flow control between adjacent routers, which prevents the flits progressing in the network and leads to a larger end-to-end delay. The amount of cycles that a packet can be stalled in the network without violating the deadline is refered to `slack'. Our buffer sizing algorithm can reduce the buffer size iteratively as long as slack is greater than zero, which can be used to reduce the router area and power consumption. But, it is significantly different from the DNC based slack optimization in \cite{6560630}. In \cite{6560630}, the energy optimization is realized by adjusting the voltage, frequency and link bandwidth of on-chip routers for the fixed configuration and deadline. In contrast, our method try to optimize the buffer size under the deadline constraint, and the buffer reduction directly leads to the area and power saving. In addition, our algorithm can be used in conjunction with the priority sharing techniques \cite{5161497} to optimize the buffer size of priority-aware wormhole-switched NoC .

\section{Experiments}\label{experiments}
In this section, we validate the correctness and tightness of our performance model by comparison with other analytical methods and simulation. Several analytical methods exist for the delay analysis of priority-aware NoC, examples include contention tree model \cite{LuJS05}, lumped link model \cite{707545}, dependency graph model \cite{708526}, FLA \cite{Shi:2008:RCA:1397757.1397996}, LLA \cite{73} and DNC \cite{Qian489900}, etc. There are also extensive research on the buffer sizing of priority-aware NoC, representative works include shaping delay analysis \cite{Manolache:2006:BSO:1131481.1131683} and LLBA \cite{189}. Among all these analytical methods, LLA \cite{73}\cite{189} and DNC \cite{Qian489900} based model outperform the others when the tightness of delay and backlog bound are considered. Thus, we will only perform comparison with LLA and DNC, as presented in subsection \ref{llacmp} and subsection \ref{dnccmp}, respectively.

\subsection{Comparison with Link Level Analysis}\label{llacmp}
The network topology and flows are shown in Fig. \ref{topology}. There are four flows (i.e. $f_1$, $f_2$, $f_3$ and $f_4$) in the network, with different priority $P_4>P_1>P_2>P_3$. Suppose the packet length of flow $f_i$ is $F_i$ (in flits) and the injection period is $I_i$. We perform the comparison on a set of periodical traffic due to the restriction of LLA method \cite{73}\cite{189}, and the traffic jitter for all the flows are set to be zero. To ease the analysis, LLA supposes the number of bits in a flit is the same as the physical channel width, and the latency of a flit traverses a router is 1 cycle. To compare with LLA, our model for the standard 5 stages wormhole router should be specialized to a single cycle router, this is achieved by letting the service curve of BW, RC, VA and ST stage be burst delay function $\delta_0(t)$. Under this condition, the service curve of entire router is the same as the service curve provided by the SA stage, which is $<\beta_{SA,R_i}^l,\beta_{SA,R_i}^u>$. In addition, the LLA method does not consider the self-blocking caused by flow control. Thus, we set the credit feedback delay $\sigma=0$ cycle in our model for a fair comparison. Next, we compare the end-to-end delay and buffer requirement computed with LLA and our model.
\subsubsection{End-to-End Delay}
For this scenario, we suppose the VC buffer is large enough so that we can ignore the back-pressure caused by flow control and directly apply LLA for the delay analysis. Suppose all the flows have the same injection period $I_i$ and packet length $F_i$, we examine the end-to-end delay of the four flows in Fig. \ref{topology} under different packet length $F_i$ and injection period $I_i$, the calculated result is shown in Table \ref{LLAvsRTC}. The RTC result is obtained by collapsing the CSP of $f_2$ (i.e. $R_{13}$ and $R_{9}$). Each quaternion in the table is corresponding to the worst-case delay of $f_1$, $f_2$, $f_3$ and $f_4$ (in cycles). The blanking items corresponding to LLA columns indicate that the worst-case delay of a flow is greater than its injection period which is unable to be analyzed with LLA \cite{73}\cite{189}, and the blanking items corresponding to RTC columns indicate that the network is unstable because the injection rate exceeds the processing capability of the network. As shown in Table \ref{LLAvsRTC}, the RTC method is applicable to these scenarios which can not be analyzed by LLA and give the worst-case delay. In addition, we also observed from the table that the RTC result is as tight as that of LLA except for the scenarios that the worst-case delay of a flow is close to the injection period, e.g. $F_i=1$, $I_i=6$ in Table \ref{LLAvsRTC}. The root source of these exceptions is due to the fact that RTC theory we used in this paper is a count-based algebra approach \cite{Phan2008MultiMode}, which ignores the state information of entire network.
\begin{table}[htbp]
\centering
\caption{\label{LLAvsRTC}Delay comparison with link level analysis}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multirow{3}{*}{$I_i$}  & \multicolumn{2}{|c|}{$F_i=1$} & \multicolumn{2}{|c|}{$F_i=2$}    &   \multicolumn{2}{|c|}{$F_i=4$} \\
\cline{2-7}
& RTC & LLA & RTC & LLA &   RTC &   LLA\\
\hline
$3$ &   7,7,8,4 &   --- &   --- &   ---   &      --- &   --- \\
\hline
$4$ &   6,6,6,4 &   --- &   --- &   ---   &      --- &   --- \\
\hline
$5$ &   6,6,6,4 &   --- &   9,10,12,5 &   ---   &      --- &   --- \\
\hline
$6$ &   5,6,6,4 &   5,6,5,4 &   9,8,9,5 &   ---   &      --- &   --- \\
\hline
$7$ &   5,6,5,4 &   5,6,5,4 &   9,8,9,5 &   --- &      --- &   --- \\
\hline
$8$ &   5,6,5,4 &   5,6,5,4 &   7,8,9,5 &   7,8,7,5 &      --- &   --- \\
\hline
$9$ &   5,6,5,4 &   5,6,5,4 &   7,8,9,5 &   7,8,7,5 &   15,16,19,7 &   --- \\
\hline
$10$    &   5,6,5,4 &   5,6,5,4 &   7,8,7,5 &   7,8,7,5 &   15,12,15,7  &   ---\\
\hline
$11$    &   5,6,5,4 &   5,6,5,4 &   7,8,7,5 &   7,8,7,5 &   15,12,15,7  &   ---\\
\hline
$12$    &   5,6,5,4 &   5,6,5,4 &   7,8,7,5 &   7,8,7,5 &   11,12,15,7  &   ---\\
\hline
$13$    &   5,6,5,4 &   5,6,5,4 &   7,8,7,5 &   7,8,7,5 &   11,12,15,7  &   ---\\
\hline
$14$    &   5,6,5,4 &   5,6,5,4 &   7,8,7,5 &   7,8,7,5 &   11,12,15,7  &   ---\\
\hline
$15$    &   5,6,5,4 &   5,6,5,4 &   7,8,7,5 &   7,8,7,5 &   11,12,15,7  &   11,12,11,7\\
\hline
$16$    &   5,6,5,4 &   5,6,5,4 &   7,8,7,5 &   7,8,7,5 &   11,12,11,7  &   11,12,11,7\\
\hline
$17$    &   5,6,5,4 &   5,6,5,4 &   7,8,7,5 &   7,8,7,5 &   11,12,11,7  &   11,12,11,7\\
\hline
\end{tabular}
\end{table}

\subsubsection{Buffer Sizing}
The LLBA method \cite{189} can only give the required buffer size at each VC to prevent flow control, because the flow control can lead to chain blocking in the network, which complicates the analysis with LLBA. Our RTC-based performance model can model the flow control behavior in a natural way, because we abstract the flow control mechanism with the wide-sense service curve. By taking the flow control into consideration, our buffer sizing algorithm can be utilized to reduce the buffer size calculated with LLBA method further as long as the deadline constraint is not violated. We take a simple example to demonstrate the strength of our method. Suppose all the flows have the same packet injection period $I_i=20$ cycles and packet length $F_i=4$ flits ($i=1,2,3,4$), we can get the end-to-end delay with LLA method for the four flows, which are (11,12,11,7) cycles. We can also get the buffer size reserved at each router for the four flows with LLBA method, which are $(1,1,1,4)$, $(4,1,1,1,1)$, $(4,4,1,1)$ and $(1,1,1,1)$, respectively. For the same configuration, if we change the deadline constraint from 15 cycles to 27 cycles, the buffer required for each flow can be further reduced with our buffer sizing algorithm, as shown in Table \ref{LLBAvsRTC}. Take the deadline $D_i=27$ as an example, the calculated buffer size is 58.62\% smaller than the total buffer size calculated with the LLBA method.
\begin{table}[htbp]
\centering
\caption{\label{LLBAvsRTC}buffer requirement computed with RTC model}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Deadline  & $f_1$  &   $f_2$   &   $f_3$   &   $f_4$   &   Total\\
\hline
(15,15,15,15)   &   (1,1,1,2)   &   (2,1,1,1,1) &   (4,4,1,1)   &   (1,1,1,1)   &   25\\
\hline
(17,17,17,17)   &   (1,1,1,2)   &   (2,1,1,1,1) &   (3,3,1,1)   &   (1,1,1,1)   &   23\\
\hline
(19,19,19,19)   &   (1,1,1,2)   &   (2,1,1,1,1) &   (2,2,1,1)   &   (1,1,1,1)   &   22\\
\hline
(21,21,21,21)   &   (1,1,1,2)   &   (1,1,1,1,1) &   (2,2,1,1)   &   (1,1,1,1)   &   20\\
\hline
(23,23,23,23)   &   (1,1,1,1)   &   (1,1,1,1,1) &   (2,2,1,1)   &   (1,1,1,1)   &   19\\
\hline
(25,25,25,25)   &   (1,1,1,1)   &   (1,1,1,1,1) &   (2,2,1,1)   &   (1,1,1,1)   &   19\\
\hline
(27,27,27,27)   &   (1,1,1,1)   &   (1,1,1,1,1) &   (1,1,1,1)   &   (1,1,1,1)   &   17\\
\hline
\end{tabular}
\end{table}

\subsection{Comparison with Network Calculus}\label{dnccmp}
In this subsection, we present the numerical results to demonstrate the improvement of our method over DNC method proposed in \cite{Qian489900}. We use the periodical traffic as an example to make the comparison. Denote by $I_i$ the injection period, $F_i$ the packet length, the arrival curve can be easily obtained according to the method introduced in subsection \ref{traffic}. Suppose the priority of each flow in Fig. \ref{topology} satisfy $P_4=P_1>P_2>P_3$, the buffer depth at each router as $B=15$ flits, credit feedback delay $\sigma=0$ cycle. Define injection rate $V_i=F_i/I_i$, we change $V_i$ ($i=1,2,3,4$) from $1/3$ flits/cycle to $1/6$ flits/cycle and packet length from $1$ flit to $8$ flits, the end-to-end delay of flow $f_3$ calculated with DNC and our method are ploted in Fig. \ref{comparison}. By comparison, we find that our method can derive a much tighter delay bound than the DNC method proposed in \cite{Qian489900}. The rooted cause for this improvement lies in the fact that our method utilizes the maximum service curve to limit the output arrival curve, and further leads to a tighter leftover service curve for the low-priority flows. To demonstrate this, for the same configuration, we plot the calculated service curve for flow $f_2$ both with DNC and RTC in Fig. \ref{loose}. The numerical calculation was carried out with RTC toolbox. From Fig. \ref{loose}, we find that the calculated service curve with DNC indeed underestimates the service curve of $f_2$, and this underestimation directly leads to the looser delay bound when compared with our method.
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[scale=0.6]{figures/comparison.pdf}\\
  \caption{Comparison with network calculus}\label{comparison}
\end{figure}
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[scale=0.6]{figures/loose.pdf}\\
  \caption{Service curve computed with RTC and DNC}\label{loose}
\end{figure}

\subsection{Comparison with Simulation}
The correctness of our delay analysis algorithm and buffer sizing algorithm is verified by simulation. We modified the switch allocator of a modular open source NoC simulator, Heterogenous Networks-on-Chip (HNoCs) \cite{6404157}, to support fixed-priority scheduling, and collect the maximal end-to-end packet delay at each destination IP core.

\section{Conclusion}\label{conclusion}
The priority-aware wormhole-switched NoC is a promising platform for the on-chip real-time communication if the worst-case performance can be accurately analyzed and guaranteed. Simulation is not competent for this purpose because it is difficult to cover all the corner cases. In this paper, we propose an RTC based performance model to achieve this goal. We first build the traffic model and service model for this NoC, and propose a novel method to derive the upper service curve of window flow control. Compared with the FLA and LLA method which assume the router to be single cycle and free of flow control, our performance model is more general and comprehensive. Then, based on the proposed RTC model, we proposed an end-to-end delay analysis algorithm and a buffer sizing algorithm. The delay analysis algorithm can be implemented to compute the end-to-end delay for each flow automatically, and verify whether all these flows meet their deadline under this configuration. To improve the calculated delay bound, we also proposed the concept of collapsible sub-path. The proposed buffer sizing algorithm can optimize the buffer size from high-priority flows to low-priority flows. It can also be implemented to perform the buffer reduction automatically under the constraint of deadline. Compared with the DNC based performance model, our model can give tighter performance bound, because the RTC-based model take the maximum service curve and minimum arrival curve into consideration. Experimental results also illustrated that, our method indeed outperforms the conventional analytical methods, e.g. LLA and DNC, when the tightness of performance bound are considered. Our results can be applied to the mapping, routing and power optimization of NoC.

\section*{Acknowledgement}
The authors would thank the reviewers for their suggestions and comments, and all the experiments are carried out at Integrated Microsystem Lab (IML) of McGill University. This research is supported by High Technology Research and Development Program of China (Grant No. 2012AA012201, 2012AA011902).

\bibliographystyle{unsrt}
\bibliography{Docear}

\end{document} 